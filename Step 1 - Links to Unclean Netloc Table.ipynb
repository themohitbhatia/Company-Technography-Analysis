{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ***Step 1 -Fetching Technology and Netloc From Links Fetched***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "import tldextract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the links data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Step 0 - Raw Data/Website_Technography_Relationship.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://static.wixstatic.com/media/</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://static.wixstatic.com/media/0525b5_c4e2...</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>./#comp-jbgap0ye</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://static.parastorage.com/unpkg/focus-wit...</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://panorama.wixapps.net/api/v1/bulklog</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        File Name                                               Link   Status\n",
       "0  02june-fsa.com                https://static.wixstatic.com/media/  Present\n",
       "1  02june-fsa.com  https://static.wixstatic.com/media/0525b5_c4e2...  Present\n",
       "2  02june-fsa.com                                   ./#comp-jbgap0ye  Present\n",
       "3  02june-fsa.com  https://static.parastorage.com/unpkg/focus-wit...  Present\n",
       "4  02june-fsa.com        https://panorama.wixapps.net/api/v1/bulklog  Present"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data to Netloc Unclean Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the File Name and Link Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['File Name'] = df_new['File Name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['Link'] = df_new['Link'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrating Netloc Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_netloc(url):\n",
    "    try:\n",
    "        parsed_url = urlparse(str(url))\n",
    "        original_netloc = parsed_url.netloc\n",
    "        \n",
    "        # If original_netloc is empty, consider it invalid\n",
    "        if not original_netloc:\n",
    "            return None\n",
    "        \n",
    "        return original_netloc\n",
    "    except Exception as e:\n",
    "        return None  # Return None instead of an empty string\n",
    "\n",
    "def netloc_status(netloc):\n",
    "    if netloc is None:\n",
    "        return 'Absent'\n",
    "    return 'Present'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'Netloc' column by applying 'extract_netloc' function\n",
    "df_new['Netloc'] = df_new['Link'].apply(extract_netloc)\n",
    "\n",
    "# Create 'Technology_Status' column by applying 'technology_status' function to the 'Netloc' column\n",
    "df_new['Netloc_Status'] = df_new['Netloc'].apply(netloc_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>Status</th>\n",
       "      <th>Netloc</th>\n",
       "      <th>Netloc_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://static.wixstatic.com/media/</td>\n",
       "      <td>Present</td>\n",
       "      <td>static.wixstatic.com</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://static.wixstatic.com/media/0525b5_c4e2...</td>\n",
       "      <td>Present</td>\n",
       "      <td>static.wixstatic.com</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>./#comp-jbgap0ye</td>\n",
       "      <td>Present</td>\n",
       "      <td>None</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://static.parastorage.com/unpkg/focus-wit...</td>\n",
       "      <td>Present</td>\n",
       "      <td>static.parastorage.com</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://panorama.wixapps.net/api/v1/bulklog</td>\n",
       "      <td>Present</td>\n",
       "      <td>panorama.wixapps.net</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        File Name                                               Link   Status  \\\n",
       "0  02june-fsa.com                https://static.wixstatic.com/media/  Present   \n",
       "1  02june-fsa.com  https://static.wixstatic.com/media/0525b5_c4e2...  Present   \n",
       "2  02june-fsa.com                                   ./#comp-jbgap0ye  Present   \n",
       "3  02june-fsa.com  https://static.parastorage.com/unpkg/focus-wit...  Present   \n",
       "4  02june-fsa.com        https://panorama.wixapps.net/api/v1/bulklog  Present   \n",
       "\n",
       "                   Netloc Netloc_Status  \n",
       "0    static.wixstatic.com       Present  \n",
       "1    static.wixstatic.com       Present  \n",
       "2                    None        Absent  \n",
       "3  static.parastorage.com       Present  \n",
       "4    panorama.wixapps.net       Present  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name          51644\n",
       "Link             4421980\n",
       "Status                 2\n",
       "Netloc            160479\n",
       "Netloc_Status          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Unclean table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_new.to_csv('Step 1 - Links to Unclean Netloc Table/Unclean_Company_Technography_Relationship.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a New Table having unique combnaion of File Name and Netloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name     50314\n",
       "Netloc       160479\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[df_new['Netloc'].notnull()][['File Name', 'Netloc']].drop_duplicates().nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique combinations of 'File Name' and 'Netloc', excluding null 'Netloc'\n",
    "df_unique = df_new[df_new['Netloc'].notnull()][['File Name', 'Netloc']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column based on substring comparison\n",
    "df_unique['Netloc_Type'] = df_unique.apply(lambda row: 'Internal' if row['File Name'] in row['Netloc'] else 'External', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name       50314\n",
       "Netloc         160479\n",
       "Netloc_Type         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.to_csv('Step 1 - Links to Unclean Netloc Table/Unclean_Company_Link_Relationship.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ***---------------------- END OF STEP 1 ---------------------***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Netloc Table from File Name Netloc Relationship Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with unique 'Netloc' values where 'Netloc_Type' is 'External'\n",
    "netloc_table = df_unique[df_unique['Netloc_Type'] == 'External']['Netloc'].drop_duplicates().reset_index(drop=True).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Netloc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static.wixstatic.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static.parastorage.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>panorama.wixapps.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.instagram.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frog.wix.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105994</th>\n",
       "      <td>techvorm.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105995</th>\n",
       "      <td>zyppysimages.s3.ap-south-1.amazonaws.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105996</th>\n",
       "      <td>www.zzcraftsman.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105997</th>\n",
       "      <td>ppnp.ac.id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105998</th>\n",
       "      <td>www.highcpmgate.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105999 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Netloc\n",
       "0                           static.wixstatic.com\n",
       "1                         static.parastorage.com\n",
       "2                           panorama.wixapps.net\n",
       "3                              www.instagram.com\n",
       "4                                   frog.wix.com\n",
       "...                                          ...\n",
       "105994                              techvorm.com\n",
       "105995  zyppysimages.s3.ap-south-1.amazonaws.com\n",
       "105996                       www.zzcraftsman.com\n",
       "105997                                ppnp.ac.id\n",
       "105998                       www.highcpmgate.com\n",
       "\n",
       "[105999 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netloc_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Domain and Subdomain Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract subdomain and second-level domain (SLD)\n",
    "def extract_subdomain_sld(netloc):\n",
    "    ext = tldextract.extract(netloc)\n",
    "    return pd.Series([ext.subdomain, ext.domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply the function to the DataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m netloc_table[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubdomain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDomain\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m netloc_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNetloc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(extract_subdomain_sld)\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4759\u001b[0m         func,\n\u001b[0;32m   4760\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4761\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4762\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4763\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4764\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1290\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1291\u001b[0m )\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m, in \u001b[0;36mextract_subdomain_sld\u001b[1;34m(netloc)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_subdomain_sld\u001b[39m(netloc):\n\u001b[0;32m      3\u001b[0m     ext \u001b[38;5;241m=\u001b[39m tldextract\u001b[38;5;241m.\u001b[39mextract(netloc)\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries([ext\u001b[38;5;241m.\u001b[39msubdomain, ext\u001b[38;5;241m.\u001b[39mdomain])\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:516\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    514\u001b[0m manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 516\u001b[0m     data \u001b[38;5;241m=\u001b[39m SingleBlockManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index, refs\u001b[38;5;241m=\u001b[39mrefs)\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    518\u001b[0m     data \u001b[38;5;241m=\u001b[39m SingleArrayManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index)\n",
      "File \u001b[1;32mc:\\Users\\mohit\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1833\u001b[0m, in \u001b[0;36mSingleBlockManager.from_array\u001b[1;34m(cls, array, index, refs)\u001b[0m\n\u001b[0;32m   1829\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1830\u001b[0m \u001b[38;5;124;03mConstructor for if we have an array that is not yet a Block.\u001b[39;00m\n\u001b[0;32m   1831\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1832\u001b[0m array \u001b[38;5;241m=\u001b[39m maybe_coerce_values(array)\n\u001b[1;32m-> 1833\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(index)))\n\u001b[0;32m   1834\u001b[0m block \u001b[38;5;241m=\u001b[39m new_block(array, placement\u001b[38;5;241m=\u001b[39mbp, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, refs\u001b[38;5;241m=\u001b[39mrefs)\n\u001b[0;32m   1835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(block, index)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Apply the function to the DataFrame\n",
    "netloc_table[['Subdomain', 'Domain']] = netloc_table['Netloc'].apply(extract_subdomain_sld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Netloc</th>\n",
       "      <th>Subdomain</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static.wixstatic.com</td>\n",
       "      <td>static</td>\n",
       "      <td>wixstatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static.parastorage.com</td>\n",
       "      <td>static</td>\n",
       "      <td>parastorage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>panorama.wixapps.net</td>\n",
       "      <td>panorama</td>\n",
       "      <td>wixapps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.instagram.com</td>\n",
       "      <td>www</td>\n",
       "      <td>instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frog.wix.com</td>\n",
       "      <td>frog</td>\n",
       "      <td>wix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105994</th>\n",
       "      <td>techvorm.com</td>\n",
       "      <td></td>\n",
       "      <td>techvorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105995</th>\n",
       "      <td>zyppysimages.s3.ap-south-1.amazonaws.com</td>\n",
       "      <td>zyppysimages.s3.ap-south-1</td>\n",
       "      <td>amazonaws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105996</th>\n",
       "      <td>www.zzcraftsman.com</td>\n",
       "      <td>www</td>\n",
       "      <td>zzcraftsman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105997</th>\n",
       "      <td>ppnp.ac.id</td>\n",
       "      <td></td>\n",
       "      <td>ppnp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105998</th>\n",
       "      <td>www.highcpmgate.com</td>\n",
       "      <td>www</td>\n",
       "      <td>highcpmgate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Netloc                   Subdomain  \\\n",
       "0                           static.wixstatic.com                      static   \n",
       "1                         static.parastorage.com                      static   \n",
       "2                           panorama.wixapps.net                    panorama   \n",
       "3                              www.instagram.com                         www   \n",
       "4                                   frog.wix.com                        frog   \n",
       "...                                          ...                         ...   \n",
       "105994                              techvorm.com                               \n",
       "105995  zyppysimages.s3.ap-south-1.amazonaws.com  zyppysimages.s3.ap-south-1   \n",
       "105996                       www.zzcraftsman.com                         www   \n",
       "105997                                ppnp.ac.id                               \n",
       "105998                       www.highcpmgate.com                         www   \n",
       "\n",
       "             Domain  \n",
       "0         wixstatic  \n",
       "1       parastorage  \n",
       "2           wixapps  \n",
       "3         instagram  \n",
       "4               wix  \n",
       "...             ...  \n",
       "105994     techvorm  \n",
       "105995    amazonaws  \n",
       "105996  zzcraftsman  \n",
       "105997         ppnp  \n",
       "105998  highcpmgate  \n",
       "\n",
       "[105999 rows x 3 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netloc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netloc_table.to_csv('Step 3 - Creating Netloc Table\\\\Netloc_Table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Unclean Relationship Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates from the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_duplicates = df.drop_duplicates(subset=['File Name', 'Link'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Function of Technology Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def technology_cleaning_function(df):\n",
    "    # Ensure 'Technology' column exists in the DataFrame\n",
    "    if 'Technology' in df.columns:\n",
    "        # Define a list of patterns to remove\n",
    "        patterns_to_remove = [\"www\", \"www')\", \"www'\", \"www<\", \"www&\", \"www')+\"]\n",
    "\n",
    "        # Remove rows where 'Technology' column matches any pattern in patterns_to_remove\n",
    "        df = df[~df['Technology'].isin(patterns_to_remove)]\n",
    "        \n",
    "        # Remove substrings that start with \"|www.\"\n",
    "        df = df[~df['Technology'].str.contains(r'\\|www\\.', case=False, na=False)]\n",
    "        \n",
    "        # Remove special characters from start or end of values in 'Technology' column\n",
    "        df['Technology'] = df['Technology'].apply(lambda x: re.sub(r'^[^a-zA-Z0-9]+|[^a-zA-Z0-9]+$', '', str(x)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_without_duplicates = technology_cleaning_function(df_without_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Clean Realtionship Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_without_duplicates.to_csv('Step 2 - Unclean to Clean relationship Table/Clean_Company_Technography_Relationship.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation of Cleaned Data for scoring Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['connect.facebook.net', 'connect.facebook.net><script',\n",
       "       'connect.facebook.com', 'connect.facebook.net><link',\n",
       "       'static.ak.connect.facebook.com'], dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df_without_duplicates[cleaned_df_without_duplicates['Technology'].str.contains(\"connect.facebook\")]['Technology'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name              51644\n",
       "Link                 4419960\n",
       "Status                     2\n",
       "Netloc                158463\n",
       "Technology            147670\n",
       "Technology_Status          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df_without_duplicates.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Technology Details table from Relationship Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Technology_Details = pd.DataFrame(cleaned_df_without_duplicates['Technology'].drop_duplicates().reset_index(drop=True), columns=['Technology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Technology_Details.to_csv('Step 4 - Relationship Table To Technology Details Table/Technology_Details.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
