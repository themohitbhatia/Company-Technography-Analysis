{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohit\\anaconda3\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "import tldextract\n",
    "from ydata_profiling import ProfileReport\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ***Step 1 -Fetching Technology and Netloc From Links Fetched***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the links data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Step 0 - Raw Data/Website_Technography_Relationship.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://static.wixstatic.com/media/</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://static.wixstatic.com/media/0525b5_c4e2...</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>./#comp-jbgap0ye</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://static.parastorage.com/unpkg/focus-wit...</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://panorama.wixapps.net/api/v1/bulklog</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        File Name                                               Link   Status\n",
       "0  02june-fsa.com                https://static.wixstatic.com/media/  Present\n",
       "1  02june-fsa.com  https://static.wixstatic.com/media/0525b5_c4e2...  Present\n",
       "2  02june-fsa.com                                   ./#comp-jbgap0ye  Present\n",
       "3  02june-fsa.com  https://static.parastorage.com/unpkg/focus-wit...  Present\n",
       "4  02june-fsa.com        https://panorama.wixapps.net/api/v1/bulklog  Present"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data to Netloc Unclean Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the File Name and Link Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['File Name'] = df_new['File Name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['Link'] = df_new['Link'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrating Netloc Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_netloc(url):\n",
    "    try:\n",
    "        parsed_url = urlparse(str(url))\n",
    "        original_netloc = parsed_url.netloc\n",
    "        \n",
    "        # If original_netloc is empty, consider it invalid\n",
    "        if not original_netloc:\n",
    "            return None\n",
    "        \n",
    "        return original_netloc\n",
    "    except Exception as e:\n",
    "        return None  # Return None instead of an empty string\n",
    "\n",
    "def netloc_status(netloc):\n",
    "    if netloc is None:\n",
    "        return 'Absent'\n",
    "    return 'Present'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'Netloc' column by applying 'extract_netloc' function\n",
    "df_new['Netloc'] = df_new['Link'].apply(extract_netloc)\n",
    "\n",
    "# Create 'Technology_Status' column by applying 'technology_status' function to the 'Netloc' column\n",
    "df_new['Netloc_Status'] = df_new['Netloc'].apply(netloc_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>Status</th>\n",
       "      <th>Netloc</th>\n",
       "      <th>Netloc_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://static.wixstatic.com/media/</td>\n",
       "      <td>Present</td>\n",
       "      <td>static.wixstatic.com</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://static.wixstatic.com/media/0525b5_c4e2...</td>\n",
       "      <td>Present</td>\n",
       "      <td>static.wixstatic.com</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>./#comp-jbgap0ye</td>\n",
       "      <td>Present</td>\n",
       "      <td>None</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://static.parastorage.com/unpkg/focus-wit...</td>\n",
       "      <td>Present</td>\n",
       "      <td>static.parastorage.com</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>https://panorama.wixapps.net/api/v1/bulklog</td>\n",
       "      <td>Present</td>\n",
       "      <td>panorama.wixapps.net</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        File Name                                               Link   Status  \\\n",
       "0  02june-fsa.com                https://static.wixstatic.com/media/  Present   \n",
       "1  02june-fsa.com  https://static.wixstatic.com/media/0525b5_c4e2...  Present   \n",
       "2  02june-fsa.com                                   ./#comp-jbgap0ye  Present   \n",
       "3  02june-fsa.com  https://static.parastorage.com/unpkg/focus-wit...  Present   \n",
       "4  02june-fsa.com        https://panorama.wixapps.net/api/v1/bulklog  Present   \n",
       "\n",
       "                   Netloc Netloc_Status  \n",
       "0    static.wixstatic.com       Present  \n",
       "1    static.wixstatic.com       Present  \n",
       "2                    None        Absent  \n",
       "3  static.parastorage.com       Present  \n",
       "4    panorama.wixapps.net       Present  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name          51644\n",
       "Link             4421980\n",
       "Status                 2\n",
       "Netloc            160479\n",
       "Netloc_Status          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Unclean table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_new.to_csv('Step 1 - Links to Unclean Netloc Table/Unclean_Company_Technography_Relationship.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a New Table having unique combnaion of File Name and Netloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name     50314\n",
       "Netloc       160479\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[df_new['Netloc'].notnull()][['File Name', 'Netloc']].drop_duplicates().nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique combinations of 'File Name' and 'Netloc', excluding null 'Netloc'\n",
    "df_unique = df_new[df_new['Netloc'].notnull()][['File Name', 'Netloc']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column based on substring comparison\n",
    "df_unique['Netloc_Type'] = df_unique.apply(lambda row: 'Internal' if row['File Name'] in row['Netloc'] else 'External', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name       50314\n",
       "Netloc         160479\n",
       "Netloc_Type         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.to_csv('Step 1 - Links to Unclean Netloc Table/Unclean_Company_Link_Relationship.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ***---------------------- END OF STEP 1 ---------------------***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ***Step 2 - Cleaning of Netloc Table***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unclean_df = pd.read_csv(r'Step 1 - Links to Unclean Netloc Table\\Unclean_Company_Link_Relationship.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Netloc</th>\n",
       "      <th>Netloc_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>static.wixstatic.com</td>\n",
       "      <td>External</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>static.parastorage.com</td>\n",
       "      <td>External</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>panorama.wixapps.net</td>\n",
       "      <td>External</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>www.02june-fsa.com</td>\n",
       "      <td>Internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>www.instagram.com</td>\n",
       "      <td>External</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         File Name                  Netloc Netloc_Type\n",
       "0   02june-fsa.com    static.wixstatic.com    External\n",
       "3   02june-fsa.com  static.parastorage.com    External\n",
       "4   02june-fsa.com    panorama.wixapps.net    External\n",
       "5   02june-fsa.com      www.02june-fsa.com    Internal\n",
       "11  02june-fsa.com       www.instagram.com    External"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name      622896\n",
       "Netloc         622896\n",
       "Netloc_Type    622896\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url(url):\n",
    "    if pd.isna(url) or not isinstance(url, str):\n",
    "        return None\n",
    "    \n",
    "    # Function to clean URL and handle special cases\n",
    "    \n",
    "    # Remove special characters from start and end, except for '*.'\n",
    "    cleaned_url = re.sub(r'^(?![*]\\.)[^\\w]+|[^\\w]+$', '', url)\n",
    "    \n",
    "    # Replace '-com.' with '.com.'\n",
    "    cleaned_url = cleaned_url.replace('-com.', '.com.')\n",
    "    \n",
    "    # Remove 'www-', 'www1-', 'www2-', etc. from the beginning\n",
    "    cleaned_url = re.sub(r'^www\\d?-', '', cleaned_url)\n",
    "    \n",
    "    # Remove 'www.', 'www1.', 'www2.', etc. from the beginning (in case it wasn't removed by previous step)\n",
    "    cleaned_url = re.sub(r'^www\\d?\\.', '', cleaned_url)\n",
    "    \n",
    "    # Nullify the value if it does not contain a period, or contains only digits\n",
    "    if '.' not in cleaned_url or cleaned_url.isdigit():\n",
    "        return None\n",
    "    \n",
    "    # Nullify the value if it contains only numbers and starts with \"mail.\" or \"www-\"\n",
    "    if re.match(r'^[\\d\\W_]+$', cleaned_url) or cleaned_url.startswith('www-'):\n",
    "        return None\n",
    "    \n",
    "    # Convert to numeric and check if it's numeric after cleaning\n",
    "    try:\n",
    "        numeric_value = pd.to_numeric(cleaned_url, errors='raise')\n",
    "        if pd.notna(numeric_value):\n",
    "            return None\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "    \n",
    "    # Remove substring matching the condition if present\n",
    "    cleaned_url = re.sub(r'.*[\\W\\d]$', '', cleaned_url)\n",
    "    \n",
    "    # Reapply the cleaning to ensure no special characters at start or end except '*.'\n",
    "    cleaned_url = re.sub(r'^(?![*]\\.)[^\\w]+|[^\\w]+$', '', cleaned_url)\n",
    "    \n",
    "    return cleaned_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'url' column and store cleaned values in a new column 'clean_url'\n",
    "clean_df['Clean_Netloc'] = clean_df['Netloc'].apply(clean_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name        50314\n",
       "Netloc          160479\n",
       "Netloc_Type          2\n",
       "Clean_Netloc    147394\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.nunique()\n",
    "# 147583\n",
    "# 147857\n",
    "# 147823\n",
    "# 147387\n",
    "\n",
    "#for actual 147394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_unique = clean_df[clean_df['Clean_Netloc'].notnull()].drop_duplicates(subset=['File Name', 'Clean_Netloc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name        50307\n",
       "Netloc          149711\n",
       "Netloc_Type          2\n",
       "Clean_Netloc    147394\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df_unique.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_unique.to_csv('Step 2 - Unclean Netloc to Clean Netloc/Clean_File_Name_Netloc_relationship_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ***---------------------- END OF STEP 2 ---------------------***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ***Step 3 - Filtering the Unique Technography Table***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the words to search for\n",
    "keywords = [\n",
    "              'connect.facebook.com',\n",
    "              'business.facebook.com',\n",
    "              'facebook.com', 'connect.facebook.net', 'm.facebook.com',\n",
    "              \"googletagmanager.com\",\n",
    "              \"google-analytics.com\",\n",
    "              \"adservice.google.co\",\n",
    "              \"googleadservices.com\",\n",
    "              'instagram.com',\n",
    "              'business.instagram.com',\n",
    "              'twitter.com',\n",
    "              'linkedin',\n",
    "              'amazonaws',\n",
    "              'microsoft',\n",
    "              'salesforce',\n",
    "              # 'dynamic',\n",
    "              # 'crm',\n",
    "              'youtube.co',\n",
    "              'youtube.com',\n",
    "              '\\\\*.youtube.com',\n",
    "              'studio.youtube.com'\n",
    "       #      'analytics'\n",
    "       #      'azure',\n",
    "]\n",
    "\n",
    "not_keywords = ['cdninstagram', 'platform.instagram.com', 'graph.instagram.com',\n",
    "       'l.instagram.com',\n",
    "       'accountscenter.instagram.com', 'api.instagram.com',\n",
    "       'secure.instagram.com', 'help.instagram.com',\n",
    "       'images.ak.instagram.com',\n",
    "       'z-p42.www.instagram.com']\n",
    "# Create a regex pattern from the keywords\n",
    "pattern = '|'.join(keywords)\n",
    "not_pattern = '|'.join(not_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame based on the pattern\n",
    "filtered_clean_df_unique = clean_df_unique[clean_df_unique['Clean_Netloc'].str.contains(pattern, case=False, na=False) & ~clean_df_unique['Clean_Netloc'].str.contains(not_pattern, case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name       34786\n",
       "Netloc           1123\n",
       "Netloc_Type         2\n",
       "Clean_Netloc     1086\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_clean_df_unique.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_clean_df_unique.to_csv('Step 3 - Clean Netloc to Filtered Clean Netloc/Filtered_Clean_File_Name_Netloc_relationship_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ***---------------------- END OF STEP 3 ---------------------***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ***Step 4 - Transforming the Filtered Data***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_links(df, column_name):\n",
    "    # Define a function to clean each link based on the conditions\n",
    "    def clean_link(link):\n",
    "        if \"google.com\" in link:\n",
    "            # Split the link at \"google.com\" and keep only the part before it and \"google.com\"\n",
    "            cleaned_link = link.split(\"google.com\")[0] + \"google.com\"\n",
    "            return cleaned_link\n",
    "        elif \"instagram.com\" in link:\n",
    "            # Split the link at \"instagram.com\" and keep only the part before it and \"instagram.com\"\n",
    "            cleaned_link = link.split(\"instagram.com\")[0] + \"instagram.com\"\n",
    "            return cleaned_link\n",
    "        return link\n",
    "\n",
    "    # Apply the cleaning function to the specified column\n",
    "    df[column_name] = df[column_name].apply(clean_link)\n",
    "    \n",
    "    # Replace links that start with \"google.com\" or \"instagram.com\" with the base domain\n",
    "    df[column_name] = df[column_name].apply(lambda x: \"google.com\" if x.startswith(\"google.com\") else (\"instagram.com\" if x.startswith(\"instagram.com\") else x))\n",
    "\n",
    "    # Replace entire value with \"amazonaws.com\" if the condition is met\n",
    "    df.loc[~df['Clean_Netloc'].str.startswith('amazonaws.com') & df['Clean_Netloc'].str.contains('amazonaws.com'), column_name] = \"amazonaws.com\"\n",
    "    \n",
    "    # Dictionary of additional domains to check for and their replacement values\n",
    "    additional_domains = {\n",
    "        \"googleadservices.com\": \"googleadservices.com\",\n",
    "        \"googletagmanager.com\": \"googletagmanager.com\",\n",
    "        \"googleusercontent.com\": \"googleusercontent.com\",\n",
    "        \"googleapis.com\": \"googleapis.com\",\n",
    "        \".google.com\": \"*.google.com\",\n",
    "        \"google-anlytics.com\": \"googleanalytics.com\",\n",
    "        \"google-analytics.com\": \"googleanalytics.com\",\n",
    "        'm.instagram.com': 'instagram.com',\n",
    "        \"connect.facebook\": \"connect.facebook.com\",\n",
    "        'dynamics.com': 'dynamics.com',\n",
    "        'youtube.co': 'youtube.com',\n",
    "        'm.facebook.com': 'facebook.com',\n",
    "        'adservice.google.co': 'adservice.google.co',\n",
    "        'microsoft.scloud': 'microsoft.scloud',\n",
    "        'microsoftcrmportals.com': 'microsoftcrmportals.com',\n",
    "        'legocrm' : 'legocrm.my.salesforce.com'\n",
    "    }\n",
    "\n",
    "    # Replace the whole value with the specified domain if any of the additional conditions are met\n",
    "    for domain, replacement in additional_domains.items():\n",
    "        if domain.startswith('.'):\n",
    "            df.loc[df[column_name].str.contains(domain[1:], regex=True), column_name] = replacement\n",
    "        else:\n",
    "            df.loc[df[column_name].str.contains(domain), column_name] = replacement\n",
    "    \n",
    "    # Retain specific facebook subdomains and nullify others\n",
    "    facebook_allowed = ['facebook.com', 'connect.facebook.com', 'm.facebook.com', 'business.facebook.com']\n",
    "    df.loc[df[column_name].str.contains('facebook') & ~df['Clean_Netloc'].isin(facebook_allowed), column_name] = np.nan\n",
    "    \n",
    "    # Additional condition for linkedin.com\n",
    "    linkedin_allowed = ['*.linkedin.com', 'business.linkedin.com']\n",
    "    df.loc[df[column_name].str.contains('linkedin') & ~df[column_name].isin(linkedin_allowed), column_name] = 'linkedin.com'\n",
    "    # Additional condition for Twitter.com\n",
    "\n",
    "    twitter_allowed = [\n",
    "        'static.ads-twitter.com', 'twitter.com',\n",
    "        'mobile.twitter.com', 'business.twitter.com', 'www.twitter.com',\n",
    "        'm.twitter.com', 'wwww.twitter.com'\n",
    "    ]\n",
    "    df.loc[df[column_name].str.contains('twitter') & ~df[column_name].isin(twitter_allowed), column_name] = np.nan\n",
    "\n",
    "    # Replace specific Twitter subdomains with \"twitter.com\"\n",
    "    twitter_specific = ['mobile.twitter.com', 'm.twitter.com', 'wwww.twitter.com']\n",
    "    df.loc[df[column_name].isin(twitter_specific), column_name] = 'twitter.com'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohit\\AppData\\Local\\Temp\\ipykernel_6752\\3826111741.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].apply(clean_link)\n",
      "C:\\Users\\mohit\\AppData\\Local\\Temp\\ipykernel_6752\\3826111741.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].apply(lambda x: \"google.com\" if x.startswith(\"google.com\") else (\"instagram.com\" if x.startswith(\"instagram.com\") else x))\n"
     ]
    }
   ],
   "source": [
    "transformed_cleaned_df = clean_links(filtered_clean_df_unique, 'Clean_Netloc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Netloc</th>\n",
       "      <th>Netloc_Type</th>\n",
       "      <th>Clean_Netloc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>www.instagram.com</td>\n",
       "      <td>External</td>\n",
       "      <td>instagram.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>02june-fsa.com</td>\n",
       "      <td>www.facebook.com</td>\n",
       "      <td>External</td>\n",
       "      <td>facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0throot.com</td>\n",
       "      <td>www.linkedin.com</td>\n",
       "      <td>External</td>\n",
       "      <td>linkedin.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1-enterprise.com</td>\n",
       "      <td>www.googletagmanager.com</td>\n",
       "      <td>External</td>\n",
       "      <td>googletagmanager.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>100kmph.com</td>\n",
       "      <td>www.googletagmanager.com</td>\n",
       "      <td>External</td>\n",
       "      <td>googletagmanager.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418923</th>\n",
       "      <td>zyppys.com</td>\n",
       "      <td>www.twitter.com</td>\n",
       "      <td>External</td>\n",
       "      <td>twitter.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418926</th>\n",
       "      <td>zyppys.com</td>\n",
       "      <td>zyppysimages.s3.ap-south-1.amazonaws.com</td>\n",
       "      <td>External</td>\n",
       "      <td>amazonaws.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418927</th>\n",
       "      <td>zyppys.com</td>\n",
       "      <td>www.googletagmanager.com</td>\n",
       "      <td>External</td>\n",
       "      <td>googletagmanager.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418930</th>\n",
       "      <td>zyppys.com</td>\n",
       "      <td>www.facebook.com</td>\n",
       "      <td>External</td>\n",
       "      <td>facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418939</th>\n",
       "      <td>zyppys.com</td>\n",
       "      <td>www.instagram.com</td>\n",
       "      <td>External</td>\n",
       "      <td>instagram.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126499 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                File Name                                    Netloc  \\\n",
       "11         02june-fsa.com                         www.instagram.com   \n",
       "68         02june-fsa.com                          www.facebook.com   \n",
       "112           0throot.com                          www.linkedin.com   \n",
       "156      1-enterprise.com                  www.googletagmanager.com   \n",
       "208           100kmph.com                  www.googletagmanager.com   \n",
       "...                   ...                                       ...   \n",
       "5418923        zyppys.com                           www.twitter.com   \n",
       "5418926        zyppys.com  zyppysimages.s3.ap-south-1.amazonaws.com   \n",
       "5418927        zyppys.com                  www.googletagmanager.com   \n",
       "5418930        zyppys.com                          www.facebook.com   \n",
       "5418939        zyppys.com                         www.instagram.com   \n",
       "\n",
       "        Netloc_Type          Clean_Netloc  \n",
       "11         External         instagram.com  \n",
       "68         External          facebook.com  \n",
       "112        External          linkedin.com  \n",
       "156        External  googletagmanager.com  \n",
       "208        External  googletagmanager.com  \n",
       "...             ...                   ...  \n",
       "5418923    External           twitter.com  \n",
       "5418926    External         amazonaws.com  \n",
       "5418927    External  googletagmanager.com  \n",
       "5418930    External          facebook.com  \n",
       "5418939    External         instagram.com  \n",
       "\n",
       "[126499 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name       34786\n",
       "Netloc           1123\n",
       "Netloc_Type         2\n",
       "Clean_Netloc      199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_cleaned_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cleaned_df.to_csv('Step 4 - Filtered Clean Netloc to Transformed Filtered Clean Netloc/Transformed_Filtered_Clean_File_Name_Netloc_relationship_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ***---------------------- END OF STEP 4 ---------------------***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ***Step 5 - Creating the Netloc Table***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "netloc_table = transformed_cleaned_df[['Clean_Netloc']].dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean_Netloc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>instagram.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>linkedin.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>googletagmanager.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>twitter.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4567950</th>\n",
       "      <td>technet.microsoft.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122171</th>\n",
       "      <td>1ap.my.salesforce.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170078</th>\n",
       "      <td>allcargogati.my.salesforce.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170158</th>\n",
       "      <td>allcargogati.my.salesforce-sites.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333845</th>\n",
       "      <td>dynamics.microsoft.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Clean_Netloc\n",
       "11                              instagram.com\n",
       "68                               facebook.com\n",
       "112                              linkedin.com\n",
       "156                      googletagmanager.com\n",
       "242                               twitter.com\n",
       "...                                       ...\n",
       "4567950                 technet.microsoft.com\n",
       "5122171                 1ap.my.salesforce.com\n",
       "5170078        allcargogati.my.salesforce.com\n",
       "5170158  allcargogati.my.salesforce-sites.com\n",
       "5333845                dynamics.microsoft.com\n",
       "\n",
       "[199 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netloc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_technology(df):\n",
    "    # Define the groups of substrings that map to the same technology\n",
    "    technology_groups = {\n",
    "        'Microsoft': {'microsoft.scloud',\n",
    "                      'microsoftonline',\n",
    "                      'teams.microsoft',\n",
    "                      'microsoft365.com'\n",
    "                    },\n",
    "\n",
    "        'Google': {'google.com'},\n",
    "        \n",
    "        # CLOUD TECHNOLOGY\n",
    "        'Amazon AWS': {'amazonaws.com'},\n",
    "        'Microsoft Cloud': {'microsoft.scloud'},\n",
    "        'Microsoft Azure': {'azure.microsoft'},\n",
    "\n",
    "        # ADS\n",
    "        'Google Ads': {'adservice.google.co', 'googleadservices.com', 'googletagmanager', 'googleanalytics'},\n",
    "        'Facebook Connect': {'connect.facebook'},\n",
    "        'Microsoft Ads': {'advertise.bingads.microsoft'},\n",
    "        \n",
    "        # CRM\n",
    "        'Salesforce': {'salesforce'},\n",
    "        'Microsoft CRM': {'microsoftcrm'},\n",
    "        'Microsoft Dynamics 365': {'dynamics.microsoft'},\n",
    "        \n",
    "        # BUSINESS\n",
    "        'Facebook Business': {'business.facebook.com'},\n",
    "        'Linkedin Business': {'business.linkedin'},\n",
    "        'Instagram Business': {'business.instagram'},\n",
    "\n",
    "        # SOCIAL MEDIA\n",
    "        'Instagram': {'instagram.com'},\n",
    "        'Twitter': {'twitter.com'},\n",
    "        'Facebook': {'facebook.com'},\n",
    "        'Youtube': {'youtube.com'},\n",
    "        'Linkedin': {'linkedin.com'},\n",
    "\n",
    "        # Application Software\n",
    "        'Microsoft Office': {'office.com'},\n",
    "        'Microsoft Power BI' :{'powerbi.microsoft'},\n",
    "\n",
    "        'Microsoft Copilot': {'copilot.microsoft'}\n",
    "\n",
    "    }\n",
    "    \n",
    "    # Create a reverse mapping from substrings to technology\n",
    "    mapping = {key: technology for technology, keys in technology_groups.items() for key in keys}\n",
    "    \n",
    "    # Function to assign technology based on Clean_Netloc\n",
    "    def get_technology(netloc):\n",
    "        for key, value in mapping.items():\n",
    "            if key in netloc.lower():  # Convert to lower case to handle case insensitivity\n",
    "                return value\n",
    "        return 'Other'  # Default value if no match is found\n",
    "\n",
    "    # Create the new column 'technology'\n",
    "    df['technology'] = df['Clean_Netloc'].apply(get_technology)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "netloc_table = assign_technology(netloc_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_category(df):\n",
    "    # Define the groups of technologies that map to the same category\n",
    "    category_groups = {\n",
    "\n",
    "        # CRM\n",
    "        'CRM': {'Salesforce', 'Microsoft CRM', 'Microsoft Dynamics 365'},\n",
    "\n",
    "        # ADS\n",
    "        'Ads': {'Microsoft Ads', 'Facebook Connect', 'Google Ads'},\n",
    "\n",
    "        # SOCIAL MEDIA\n",
    "        'Social Media': {\n",
    "            'Youtube',\n",
    "            'Twitter', \n",
    "            'Instagram',\n",
    "            'Facebook',\n",
    "            'Linkedin'\n",
    "        },\n",
    "\n",
    "        # BUSINESS\n",
    "        'Business': {\n",
    "            'Facebook Business',\n",
    "            'Linkedin Business',\n",
    "            'Instagram Business'\n",
    "        },\n",
    "        \n",
    "\n",
    "        'Software': {'Microsoft', 'Microsoft Office', 'Google', 'Microsoft Power BI'},\n",
    "\n",
    "        'Cloud': {'Amazon AWS', 'Microsoft Cloud', 'Microsoft Azure'},\n",
    "    \n",
    "        'Other': {'Other'}\n",
    "    }\n",
    "\n",
    "\n",
    "    # Create a reverse mapping from technologies to categories\n",
    "    category_mapping = {tech: category for category, technologies in category_groups.items() for tech in technologies}\n",
    "    \n",
    "    # Function to assign category based on technology\n",
    "    def get_category(technology):\n",
    "        return category_mapping.get(technology, 'Other')\n",
    "\n",
    "    # Create the new column 'Category'\n",
    "    df['Category'] = df['technology'].apply(get_category)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "netloc_table = assign_category(netloc_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "netloc_table.to_csv('Step 5 - Creating Netloc Table/Netloc_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
